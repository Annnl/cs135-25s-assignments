{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS135 day10: Bag of Words Representations for Text Data\n",
    "\n",
    "# Background\n",
    "\n",
    "Project A requires you to consider a \"bag of words\" representation in Problem 1. \n",
    "\n",
    "See https://www.cs.tufts.edu/cs/135/2025s/projectA.html\n",
    "\n",
    "# Objectives\n",
    "\n",
    "* Understand bag of words representations\n",
    "* Think through the decision decisions you need to make and how they will impact classifier performance\n",
    "\n",
    "\n",
    "# Outline\n",
    "\n",
    "* [Part 1: Cleaning text into a list of tokens](#part1)\n",
    "* [Part 2: Building a fixed-size vocabulary](#part2)\n",
    "* [Part 3: Creating a BoW feature vector](#part3)\n",
    "* [Part 4: Building a classifier given your BoW features](#part4)\n",
    "* [Part 5: Sklearn's CountVectorizer for easy BoW feature processing](#part5)\n",
    "* [Part 6: Using a pipeline with CountVectorizer](#part6)\n",
    "\n",
    "We expect you'll get through part 4 during this class period. \n",
    "\n",
    "# Takeaways\n",
    "\n",
    "* Bag of words representations are simple and still interpretable\n",
    "* Bag of words representations are limited: you lose any information that comes from the *ordering* of the words\n",
    "* Many key design decisions (how to handle rare words, how to handle similar words like \"walk\" and \"walking\") can matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: Raw Text Data\n",
    "\n",
    "We've included some raw text from product reviews contributed to major online review aggregators (e.g. imdb, yelp, etc.). There are 200 negative reviews and 200 positive reviews below.\n",
    "\n",
    "Each line is one plain-text review. You'll see many slang terms, weird capitalization/punctuation/etc.\n",
    "\n",
    "Just execute the cell and move on. You'll need to scroll down a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_reviews_as_line_separated_string = \"\"\"Oh and I forgot to also mention the weird color effect it has on your phone.\n",
    "THAT one didn't work either.\n",
    "Waste of 13 bucks.\n",
    "Product is useless, since it does not have enough charging current to charge the 2 cellphones I was planning to use it with.\n",
    "None of the three sizes they sent with the headset would stay in my ears.\n",
    "Worst customer service.\n",
    "The Ngage is still lacking in earbuds.\n",
    "It always cuts out and makes a beep beep beep sound then says signal failed.\n",
    "the only VERY DISAPPOINTING thing was there was NO SPEAKERPHONE!!!!\n",
    "Very disappointed in AccessoryOne.\n",
    "Basically the service was very bad.\n",
    "Bad Choice.\n",
    "The only thing that disappoint me is the infra red port (irda).\n",
    "horrible, had to switch 3 times.\n",
    "It feels poorly constructed, the menus are difficult to navigate, and the buttons are so recessed that it is difficult to push them.\n",
    "Don't make the same mistake I did.\n",
    "Muddy, low quality sound, and the casing around the wire's insert was poorly super glued and slid off.\n",
    "I advise EVERYONE DO NOT BE FOOLED!\n",
    "Doesn't hold charge.\n",
    "What a waste of time!\n",
    "I'm very disappointed with my decision.\n",
    "I also didn't like the \"on\" button, it felt like it would crack with use.\n",
    "I bought these hoping I could make my Bluetooth headset fit better but these things made it impossible to wear.\n",
    "We have tried 2 units and they both failed within 2 months.. Pros\n",
    "Also difficult to put on.I'd recommend avoiding this product.\n",
    "$50 Down the drain.\n",
    "Absolutel junk.\n",
    "Can't store anything but phone numbers to SIM.\n",
    "Very disappointing.\n",
    "I would not recommend this item to anyone.\n",
    "Big Disappointment with calendar sync.\n",
    "Not impressed.\n",
    "Just does not work.\n",
    "I even fully charged it before I went to bed and turned off blue tooth and wi-fi and noticed that it only had 20 % left in the morning.\n",
    "Plus, I seriously do not believe it is worth its steep price point.\n",
    "In my house I was getting dropped coverage upstairs and no coverage in my basement.\n",
    "The phone takes FOREVER to charge like 2 to 5 hours literally.\n",
    "Very unreliable service from T-mobile !\n",
    "[...] down the drain because of a weak snap!\n",
    "This is a simple little phone to use, but the breakage is unacceptible.\n",
    "Pretty piece of junk.\n",
    "This is so embarassing and also my ears hurt if I try to push the ear plug into my ear.\n",
    "Unfortunately the ability to actually know you are receiving a call is a rather important feature and this phone is pitiful in that respect.\n",
    "This is the first phone I've had that has been so cheaply made.\n",
    "Awkward to use and unreliable.\n",
    "Horrible phone.\n",
    "If you are looking for a good quality Motorola Headset keep looking, this isn't it.\n",
    "My father has the V265, and the battery is dying.\n",
    "After a year the battery went completely dead on my headset.\n",
    "Defective crap.\n",
    "Poor Construction.\n",
    "They work about 2 weeks then break.\n",
    "Could not get strong enough signal.\n",
    "I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good\n",
    "Excellent starter wireless headset.\n",
    "Performed awful -- muffled, tinny incoming sound and severe echo for those on the other end of the call.\n",
    "BT50 battery junk!.\n",
    "The design might be ergonomic in theory but I could not stand having these in my ear.\n",
    "camera color balance is AWFUL.\n",
    "It dit not work most of the time with my Nokia 5320.\n",
    "Looks good in the picture, but this case was a huge disappointment!!\n",
    "I've had this bluetoooth headset for some time now and still not comfortable with the way it fits on the ear.\n",
    "Plug was the wrong size.\n",
    "the phone was unusable and was not new.\n",
    "If I take a picture, the battery drops a bar, and starts beeping, letting me know its dieing.\n",
    "It's so stupid to have to keep buying new chargers, car chargers, cradles, headphones and car kits every time a new phone comes out.\n",
    "poor quality and service.\n",
    "Poor product.\n",
    "I'm a bit disappointed.\n",
    "I tried talking real loud but shouting on the telephone gets old and I was still told it wasn't great.\n",
    "There's a horrible tick sound in the background on all my calls that I have never experienced before.\n",
    "The design is very odd, as the ear \"clip\" is not very comfortable at all.\n",
    "At first I thought I was grtting a good deal at $7.44, until I plugged it into my phone (V3c Razr).\n",
    "dont buy it.\n",
    "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
    "Soyo technology sucks.\n",
    "doesn't last long.\n",
    "Still Waiting...... I'm sure this item would work well.. if I ever recieve it!\n",
    "Poorly contstruct hinge.\n",
    "Think it over when you plan to own this one!This sure is the last MOTO phone for me!\n",
    "Problem is that the ear loops are made of weak material and break easily.\n",
    "The bottowm line...another worthless, cheap gimmick from Sprint.\n",
    "This pair of headphones is the worst that I have ever had sound-wise.\n",
    "Att is not clear, sound is very distorted and you have to yell when you talk.\n",
    "i would advise to not purchase this item it never worked very well.\n",
    "It doesn't make you look cool.\n",
    "Bought mainly for the charger, which broke soon after purchasing.\n",
    "I put the latest OS on it (v1.15g), and it now likes to slow to a crawl and lock up every once in a while.\n",
    "There's really nothing bad I can say about this headset.\n",
    "We are sending it back.\n",
    "I came over from Verizon because cingulair has nicer cell phones.... the first thing I noticed was the really bad service.\n",
    "Unreliable - I'm giving up.\n",
    "After my phone got to be about a year old, it's been slowly breaking despite much care on my part.\n",
    "It was a waste of my money.\n",
    "don't waste your money and time.\n",
    "Due to this happening on every call I was forced to stop using this headset.\n",
    "I checked everywhere and there is no feature for it which is really disappointing.\n",
    "Does not fit.\n",
    "I'll be looking for a new earpiece.\n",
    "However, the keypads are so tinny that I sometimes reach the wrong buttons.\n",
    "Unfortunately it did not work.\n",
    "Couldn't figure it out\n",
    "Worst software ever used.... If I could give this zero stars I would.\n",
    "Lousy product.\n",
    "Lasted one day and then blew up.\n",
    "I bought it for my mother and she had a problem with the battery.\n",
    "I was not impressed by this product.\n",
    "Not enough volume.\n",
    "Buyer--Be Very Careful!!!!!.\n",
    "Were JERKS on the phone.\n",
    "But when I check voice mail at night, the keypad backlight turns off a few seconds into the first message, and then I'm lost.\n",
    "Disapointing Results.\n",
    "I got the car charger and not even after a week the charger was broken...I went to plug it in and it started smoking.\n",
    "I find this inexcusable and so will probably be returning this phone and perhaps changing carriers.\n",
    "You get what you pay for I guess.\n",
    "Bad Quality.\n",
    "It's not what it says it is.\n",
    "It's kind of embarrassing to use because of how it looks and mostly it's embarrassing how child-like the company is.\n",
    "All in all, I'd expected a better consumer experience from Motorola.\n",
    "Sending it back.\n",
    "Everything about this product is wrong.First\n",
    "It is cheap, and it feel and look just as cheap.\n",
    "After receiving and using the product for just 2 days it broke.\n",
    "Phone falls out easily.\n",
    "The first thing that happened was that the tracking was off.\n",
    "Linksys should have some way to exchange a bad phone for a refurb unit or something!\n",
    "A must study for anyone interested in the \"worst sins\" of industrial design.\n",
    "The BT headset was such a disapoinment.\n",
    "I have had this phone for over a year now, and I will tell you, its not that great.\n",
    "What a piece of junk.. I lose more calls on this phone.\n",
    "Doesn't work at all.. I bougth it for my L7c and its not working.\n",
    "very disappointed.\n",
    "Earbud piece breaks easily.\n",
    "I can barely ever hear on it and am constantly saying \"what?\"\n",
    "It doesn't work in Europe or Asia.\n",
    "I ordered this product first and was unhappy with it immediately.\n",
    "I'm really disappointed all I have now is a charger that doesn't work.\n",
    "Horrible, horrible protector.\n",
    "Rip off---- Over charge shipping.\n",
    "Case was more or less an extra that I originally put on but later discarded because it scratched my ear.\n",
    "I've also had problems with the phone reading the memory card in which I always turn it on and then off again.\n",
    "Piece of Junk.\n",
    "The case is a flimsy piece of plastic and has no front or side protection whatsoever.\n",
    "The battery is completely useless to me.\n",
    "The biggest complaint I have is, the battery drains superfast.\n",
    "So I had to take the battery out of the phone put it all back together and then restart it.\n",
    "Bad Purchase.\n",
    "It was horrible!.\n",
    "Perhaps my phone is defective, but people cannot hear me when I use this.\n",
    "Not only will it drain your player, but may also potentially fry it.\n",
    "Improper description.... I had to return it.\n",
    "Cant get the software to work with my computer.\n",
    "I did not bother contacting the company for few dollar product but I learned the lesson that I should not have bought this form online anyway.\n",
    "Reaching for the bottom row is uncomfortable, and the send and end keys are not where I expect them to be.3.\n",
    "The calls drop, the phone comes on and off at will, the screen goes black and the worst of all it stops ringing intermittently.\n",
    "The commercials are the most misleading.\n",
    "Steer clear of this product and go with the genuine Palm replacementr pens, which come in a three-pack.\n",
    "I don't think it would hold it too securly on your belt.\n",
    "It makes very strange ticking noises before it ends the call.\n",
    "I kept catching the cable on the seat and I had to pull the phone out to turn it on an off.\n",
    "Piece of trash.\n",
    "Not a good item.. It worked for a while then started having problems in my auto reverse tape player.\n",
    "Then a few days later the a puff of smoke came out of the phone while in use.\n",
    "Then I exchanged for the same phone, even that had the same problem.\n",
    "Cumbersome design.\n",
    "All three broke within two months of use.\n",
    "One thing I hate is the mode set button at the side.\n",
    "While I managed to bend the leaf spring back in place, the metal now has enough stress that it will break on the next drop.\n",
    "The camera, although rated at an impressive 1.3 megapixels, renders images that fall well below expectations of such a relatively high resolution.\n",
    "The screen does get smudged easily because it touches your ear and face.\n",
    "Item Does Not Match Picture.\n",
    "DO NOT BUY DO NOT BUYIT SUCKS\n",
    "Doesn't Work.\n",
    "Sprint charges for this service.\n",
    "I am not impressed with this and i would not recommend this item to anyone.\n",
    "This is essentially a communications tool that does not communicate.\n",
    "stay away from this store, be careful.\n",
    "It's A PIECE OF CRAP!\n",
    "sucked, most of the stuff does not work with my phone.\n",
    "Adapter does not provide enough charging current.\n",
    "Talk about USELESS customer service.\n",
    "What a big waste of time.\n",
    "Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\n",
    "You also cannot take pictures with it in the case because the lense is covered.\n",
    "Don't make the same mistake that I did and please don't buy this phone.\n",
    "The construction of the headsets is poor.\n",
    "It's uncomfortable and the sound quality is quite poor compared with the phone (Razr) or with my previous wired headset (that plugged into an LG).\n",
    "No additional ear gels provided, and no instructions whatsoever.\n",
    "Echo Problem....Very unsatisfactory\n",
    "These products cover up the important light sensor above the ear outlet.\n",
    "And none of the tones is acceptable.\n",
    "don't waste your money.\n",
    "This is infuriating.\n",
    "The loudspeaker option is great, the bumpers with the lights is very ... appealing.\n",
    "It clicks into place in a way that makes you wonder how long that mechanism would last.\n",
    "I found this product to be waaay too big.\n",
    "The instructions didn't explain that a microphone jack could be used.\n",
    "Uncomfortable In the Ear, Don't use with LG VX9900 (EnV).\n",
    "You have to hold the phone at a particular angle for the other party to hear you clearly.\n",
    "Can't upload ringtones from a third party.\n",
    "Today is the second time I've been to their lunch buffet and it was pretty good.\n",
    "I would recommend saving room for this!\n",
    "This place receives stars for their APPETIZERS!!!\n",
    "It is PERFECT for a sit-down family meal or get together with a few friends.\n",
    "I had heard good things about this place, but it exceeding every hope I could have dreamed of.\n",
    "They were golden-crispy and delicious.\n",
    "The wontons were thin, not thick and chewy, almost melt in your mouth.\n",
    "All in all an excellent restaurant highlighted by great service, a unique menu, and a beautiful setting.\n",
    "Ample portions and good prices.\n",
    "Their regular toasted bread was equally satisfying with the occasional pats of butter... Mmmm...!\n",
    "The food was outstanding and the prices were very reasonable.\n",
    "In an interesting part of town, this place is amazing.\n",
    "I want to first say our server was great and we had perfect service.\n",
    "Im in AZ all the time and now have my new spot.\n",
    "The ambience is wonderful and there is music playing.\n",
    "This is the place where I first had pho and it was amazing!!\n",
    "Both of the egg rolls were fantastic.\n",
    "It was just not a fun experience.\n",
    "Cant say enough good things about this place.\n",
    "The bartender was also nice.\n",
    "Their steaks are 100% recommended!\n",
    "Awesome service and food.\n",
    "Our server was fantastic and when he found out the wife loves roasted garlic and bone marrow, he added extra to our meal and another marrow to go!\n",
    "A good time!\n",
    "I will come back here every time I'm in Vegas.\n",
    "The lighting is just dark enough to set the mood.\n",
    "Service was fantastic.\n",
    "A couple of months later, I returned and had an amazing meal.\n",
    "The food came out at a good pace.\n",
    "Great food and awesome service!\n",
    "I love the decor with the Chinese calligraphy wall paper.\n",
    "Service is perfect and the family atmosphere is nice to see.\n",
    "Once you get inside you'll be impressed with the place.\n",
    "Would come back again if I had a sushi craving while in Vegas.\n",
    "High-quality chicken on the chicken Caesar salad.\n",
    "We were promptly greeted and seated.\n",
    "I tried the Cape Cod ravoli, chicken,with cranberry...mmmm!\n",
    "Fantastic service here.\n",
    "Just had lunch here and had a great experience.\n",
    "The pancake was also really good and pretty large at that.\n",
    "The service was outshining & I definitely recommend the Halibut.\n",
    "I also had to taste my Mom's multi-grain pumpkin pancakes with pecan butter and they were amazing, fluffy, and delicious!\n",
    "A great way to finish a great.\n",
    "I personally love the hummus, pita, baklava, falafels and Baba Ganoush (it's amazing what they do with eggplant!).\n",
    "This place is pretty good, nice little vibe in the restaurant.\n",
    "The chicken was deliciously seasoned and had the perfect fry on the outside and moist chicken on the inside.\n",
    "So flavorful and has just the perfect amount of heat.\n",
    "This wonderful experience made this place a must-stop whenever we are in town again.\n",
    "We were sat right on time and our server from the get go was FANTASTIC!\n",
    "OMG I felt like I had never eaten Thai food until this dish.\n",
    "The sergeant pepper beef sandwich with auju sauce is an excellent sandwich as well.\n",
    "Very very fun chef.\n",
    "The food, amazing.\n",
    "An excellent new restaurant by an experienced Frenchman.\n",
    "I will be back many times soon.\n",
    "There was a warm feeling with the service and I felt like their guest for a special treat.\n",
    "The atmosphere here is fun.\n",
    "I'm so happy to be here!!!\"\n",
    "Their chow mein is so good!\n",
    "The service was great, even the manager came and helped with our table.\n",
    "Just as good as when I had it more than a year ago!\n",
    "What I really like there is the crepe station.\n",
    "It was absolutely amazing.\n",
    "Some may say this buffet is pricey but I think you get what you pay for and this place you are getting quite a lot!\n",
    "On the up side, their cafe serves really good food.\n",
    "We thought you'd have to venture further away to get good sushi, but this place really hit the spot that night.\n",
    "Everyone is treated equally special.\n",
    "This isn't a small family restaurant, this is a fine dining establishment.\n",
    "I'll definitely be in soon again.\n",
    "I miss it and wish they had one in Philadelphia!\n",
    "This is an Outstanding little restaurant with some of the Best Food I have ever tasted.\n",
    "Great place to have a couple drinks and watch any and all sporting events as the walls are covered with TV's.\n",
    "Pretty cool I would say.\n",
    "The flair bartenders are absolutely amazing!\n",
    "The croutons also taste homemade which is an extra plus.\n",
    "the potatoes were great and so was the biscuit.\n",
    "So they performed.\n",
    "It's worth driving up from Tucson!\n",
    "Best tacos in town by far!!\n",
    "The chips and salsa were really good, the salsa was very fresh.\n",
    "Our server was super nice and checked on us many times.\n",
    "The cocktails are all handmade and delicious.\n",
    "They know how to make them here.\n",
    "We made the drive all the way from North Scottsdale... and I was not one bit disappointed!\n",
    "Great service and food.\n",
    "We loved the biscuits!!!\n",
    "Definitely worth venturing off the strip for the pork belly, will return next time I'm in Vegas.\n",
    "They really want to make your experience a good one.\n",
    "Favorite place in town for shawarrrrrrma!!!!!!\n",
    "The burger is good beef, cooked just right.\n",
    "The seasonal fruit was fresh white peach puree.\n",
    "Great place to eat, reminds me of the little mom and pop shops in the San Francisco Bay Area.\n",
    "Hawaiian Breeze, Mango Magic, and Pineapple Delight are the smoothies that I've tried so far and they're all good.\n",
    "The food is good.\n",
    "The atmosphere is modern and hip, while maintaining a touch of coziness.\n",
    "Best tater tots in the southwest.\n",
    "Back to good BBQ, lighter fare, reasonable pricing and tell the public they are back to the old ways.\n",
    "Penne vodka excellent!\n",
    "I believe that this place is a great stop for those with a huge belly and hankering for sushi.\n",
    "Cute, quaint, simple, honest.\n",
    "A fantastic neighborhood gem !!!\n",
    "Now the pizza itself was good the peanut sauce was very tasty.\n",
    "It was awesome.\n",
    "The nachos are a MUST HAVE!\n",
    "I like Steiners because it's dark and it feels like a bar.\n",
    "I had the opportunity today to sample your amazing pizzas!\n",
    "At first glance it is a lovely bakery cafe - nice ambiance, clean, friendly staff.\n",
    "Waitress was good though!\n",
    "You get incredibly fresh fish, prepared with care.\n",
    "These were so good we ordered them twice.\n",
    "Service is quick and friendly.\n",
    "I liked the patio and the service was outstanding.\n",
    "All of the tapas dishes were delicious!\n",
    "In the summer, you can dine in a charming outdoor patio - so very delightful.\n",
    "They have a good selection of food including a massive meatloaf sandwich, a crispy chicken wrap, a delish tuna melt and some tasty burgers.\n",
    "The food was excellent and service was very good.\n",
    "I have been here several times in the past, and the experience has always been great.\n",
    "Great place fo take out or eat in.\n",
    "An absolute must visit!\n",
    "Very friendly staff.\n",
    "I loved the bacon wrapped dates.\n",
    "Last night was my second time dining here and I was so happy I decided to go back!\n",
    "They have a plethora of salads and sandwiches, and everything I've tried gets my seal of approval.\n",
    "The selection on the menu was great and so were the prices.\n",
    "All in all, I can assure you I'll be back.\n",
    "Great food.\n",
    "Food was good, service was good, Prices were good.\n",
    "The black eyed peas and sweet potatoes... UNREAL!\n",
    "As always the evening was wonderful and the food delicious!\n",
    "I have eaten here multiple times, and each time the food was delicious.\n",
    "My fiancé and I came in the middle of the day and we were greeted and seated right away.\n",
    "And considering the two of us left there very full and happy for about $20, you just can't go wrong.\n",
    "Great food and service, huge portions and they give a military discount.\n",
    "I *heart* this place.\n",
    "this place is good.\n",
    "I love the owner/chef, his one authentic Japanese cool dude!\n",
    "I didn't know pulled pork could be soooo delicious.\n",
    "I recently tried Caballero's and I have been back every week since!\n",
    "The food was very good and I enjoyed every mouthful, an enjoyable relaxed venue for couples small family groups etc.\n",
    "CONCLUSION: Very filling meals.\n",
    "You won't be disappointed.\n",
    "I was proven dead wrong by this sushi bar, not only because the quality is great, but the service is fast and the food, impeccable.\n",
    "The steak and the shrimp are in my opinion the best entrees at GC.\n",
    "Restaurant is always full but never a wait.\n",
    "Love this place, hits the spot when I want something healthy but not lacking in quantity or flavor.\n",
    "The fries were great too.\n",
    "I don't each much pasta, but I love the homemade /hand made pastas and thin pizzas here.\n",
    "This was my first crawfish experience, and it was delicious!\n",
    "On a positive note, our server was very attentive and provided great service.\n",
    "I had strawberry tea, which was good.\n",
    "The waitress was friendly and happy to accomodate for vegan/veggie options.\n",
    "We loved the place.\n",
    "Nice, spicy and tender.\n",
    "We walked away stuffed and happy about our first Vegas buffet experience.\n",
    "Point your finger at any item on the menu, order it and you won't be disappointed.\n",
    "The sides are delish - mixed mushrooms, yukon gold puree, white corn - beateous.\n",
    "Service was fine and the waitress was friendly.\n",
    "Generous portions and great taste.\n",
    "The roast beef sandwich tasted really good!\n",
    "Loved it...friendly servers, great food, wonderful and imaginative menu.\n",
    "I had a seriously solid breakfast here.\n",
    "We had a group of 70+ when we claimed we would only have 40 and they handled us beautifully.\n",
    "Omelets are to die for!\n",
    "They had a toro tartare with a cavier that was extraordinary and I liked the thinly sliced wagyu with white truffle.\n",
    "The grilled chicken was so tender and yellow from the saffron seasoning.\n",
    "To summarize... the food was incredible, nay, transcendant... but nothing brings me joy quite like the memory of the pneumatic condiment dispenser.\n",
    "Great food for the price, which is very high quality and house made.\n",
    "Best Buffet in town, for the price you cannot beat it.\n",
    "Anyway, this FS restaurant has a wonderful breakfast/lunch.\n",
    "The ambiance was incredible.\n",
    "The atmosphere was great with a lovely duo of violinists playing songs we requested.\n",
    "This place is amazing!\n",
    "The food was very good.\n",
    "The portion was huge!\n",
    "The goat taco didn't skimp on the meat and wow what FLAVOR!\n",
    "The food was great as always, compliments to the chef.\n",
    "* Both the Hot & Sour & the Egg Flower Soups were absolutely 5 Stars!\n",
    "He deserves 5 stars.\n",
    "Lordy, the Khao Soi is a dish that is not to be missed for curry lovers!\n",
    "This place is awesome if you want something light and healthy during the summer.\n",
    "I was seated immediately.\n",
    "I will continue to come here on ladies night andddd date night ... highly recommend this place to anyone who is in the area (;\n",
    "They also have the best cheese crisp in town.\n",
    "Food was delicious!\n",
    "Both of them were truly unbelievably good, and I am so glad we went back.\n",
    "you can watch them preparing the delicious food!)\n",
    "The cow tongue and cheek tacos are amazing.\n",
    "This was my first time and I can't wait until the next.\n",
    "The staff are also very friendly and efficient.\n",
    "Of all the dishes, the salmon was the best, but all were great.\n",
    "Food was so gooodd.\n",
    "They have great dinners.\n",
    "Best fish I've ever had in my life!\n",
    "Great brunch spot.\n",
    "I don't have very many words to say about this place, but it does everything pretty well.\n",
    "The sweet potato fries were very good and seasoned well.\n",
    "I could eat their bruschetta all day it is devine.\n",
    "Ambience is perfect.\n",
    "We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.\n",
    "Service was good and the company was better!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Cleaning text into a list of tokens\n",
    "\n",
    "Our goal here is to represent each line of text in the \"raw\" data as a list of tokens.\n",
    "\n",
    "A 'token' here is just a string of non-whitespace characters. Note that other modern language models have more advanced definitions of \"tokens\".\n",
    "\n",
    "We'll make some simple decisions:\n",
    "\n",
    "* Make everything lower case\n",
    "* Remove any punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(raw_text):\n",
    "    ''' Transform a plain-text string into a list of tokens\n",
    "    \n",
    "    We assume that *whitespace* divides tokens.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    raw_text : string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_tokens : list of strings\n",
    "        Each element is one token in the provided text\n",
    "    '''\n",
    "    list_of_tokens = raw_text.split() # split method divides on whitespace by default\n",
    "    for pp in range(len(list_of_tokens)):\n",
    "        cur_token = list_of_tokens[pp]\n",
    "        # Remove punctuation\n",
    "        for punc in ['?', '!', '_', '.', ',', '\"', '/']:\n",
    "            cur_token = cur_token.replace(punc, \"\")\n",
    "        # Turn to lower case\n",
    "        clean_token = cur_token.lower()\n",
    "        # Replace the cleaned token into the original list\n",
    "        list_of_tokens[pp] = clean_token\n",
    "    return list_of_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of turning the text into a list of tokens\n",
    "\n",
    "Lets show the raw and token-list representations of the first 10 lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw text:\n",
      "The 5th vol contains the Index by Bomtz,  1831-70, Didot edition (Greek and Latin), 5 vols 1848 74    ENGLISH TRANSLATIONS Edited by T Taylor, with Porphyry's Introduction,  9 vols, 1812, under editorship of J A Smith and W D Ross, II vols,  1908-31, Loeb editions Ethica, Rhetorica, Poetica, Physica, Politica,  Metaphysica, 1926-33    Later editions of separate works _De Anima_ Torstrik, 1862,  Trendelenburg, 2nd edition, 1877, with English translation, L Wallace,  1882, Biehl, 1884, 1896, with English, R D Hicks, 1907 _Ethica_ J S  Brewer (Nicomachean), 1836, W E Jelf, 1856, J F T Rogers, 1865, A  Grant, 1857 8, 1866, 1874, 1885, E Moore, 1871, 1878, 4th edition,  1890, Ramsauer (Nicomachean), 1878, Susemihl, 1878, 1880, revised by O  Apelt, 1903, A Grant, 1885, I Bywater (Nicomachean), 1890, J Burnet,  1900    _Historia Animalium_ Schneider, 1812, Aubert and Wimmer, 1860;  Dittmeyer, 1907    _Metaphysica_ Schwegler, 1848, W Christ, 1899    _Organon_ Waitz, 1844 6    _Poetica_ Vahlen, 1867, 1874, with Notes by E Moore, 1875, with English  translation by E R Wharton, 1883, 1885, Uberweg, 1870, 1875, with  German translation, Susemihl, 1874, Schmidt, 1875, Christ, 1878, I  Bywater, 1898, T G Tucker, 1899    _De Republica Athenientium_ Text and facsimile of Papyrus, F G Kenyon,  1891, 3rd edition, 1892, Kaibel and Wilamowitz-Moellendorf, 1891, 3rd  edition, 1898, Van Herwerden and Leeuwen (from Kenyon's text), 1891,  Blass, 1892, 1895, 1898, 1903, J E Sandys, 1893    _Politica_ Susemihl, 1872, with German, 1878, 3rd edition, 1882,  Susemihl and Hicks, 1894, etc, O Immisch, 1909    _Physica_ C Prantl, 1879    _Rhetorica_ Stahr, 1862, Sprengel (with Latin text), 1867, Cope and  Sandys, 1877, Roemer, 1885, 1898    ENGLISH TRANSLATIONS OF ONE OR MORE WORKS De Anima (with Parva  Naturalia), by W A Hammond, 1902 Ethica Of Morals to Nicomachus, by E  Pargiter, 1745, with Politica by J Gillies, 1797, 1804, 1813, with  Rhetorica and Poetica, by T Taylor, 1818, and later editions  Nicomachean Ethics, 1819, mainly from text of Bekker by D P Chase,  1847, revised 1861, and later editions, with an introductory essay by G  H Lewes (Camelot Classics) 1890, re-edited by J M Mitchell (New  Universal Library), 1906, 1910, by R W Browne (Bohn's Classical  Library), 1848, etc, by R Williams, 1869, 1876, by W M Hatch and others  (with translation of paraphrase attributed to Andronicus of Rhodes),  edited by E Hatch, 1879 by F H Peters, 1881, J E C Welldon, 1892, J  Gillies (Lubbock's Hundred Books) 1893 Historia Animalium, by R  Creswell (Bonn's Classical Library) 1848, with Treatise on Physiognomy,  by T Taylor, 1809 Metaphysica, by T Taylor, 1801, by J H M Mahon  (Bohn's Classical Library), 1848 Organon, with Porphyry's Introduction,  by O F Owen (Bohn's Classical Library), 1848 Posterior Analytics, E  Poste, 1850, E S Bourchier, 1901, On Fallacies, E Poste, 1866 Parva  Naturaha (Greek and English), by G R T Ross, 1906, with De Anima, by W  A Hammond, 1902 Youth and Old Age, Life and Death and Respiration, W  Ogle 1897 Poetica, with Notes from the French of D Acier, 1705, by H J  Pye, 1788, 1792, T Twining, 1789, 1812, with Preface and Notes by H  Hamilton, 1851, Treatise on Rhetorica and Poetica, by T Hobbes (Bohn's  Classical Library), 1850, by Wharton, 1883 (see Greek version), S H  Butcher, 1895, 1898, 3rd edition, 1902, E S Bourchier, 1907, by Ingram  Bywater, 1909 De Partibus Animalium, W Ogle, 1882 De Republica  Athenientium, by E Poste, 1891, F G Kenyon, 1891, T J Dymes, 1891 De  Virtutibus et Vitus, by W Bridgman, 1804 Politica, from the French of  Regius, 1598, by W Ellis, 1776, 1778, 1888 (Morley's Universal  Library), 1893 (Lubbock's Hundred Books) by E Walford (with Æconomics,  and Life by Dr Gillies), (Bohn's Classical Library), 1848, J E. C.  Welldon, 1883, B Jowett, 1885, with Introduction and Index by H W C  Davis, 1905, Books i iii iv (vii) from Bekker's text by W E Bolland,  with Introduction by A Lang, 1877.\n",
      "Clean token list:\n",
      "['the', '5th', 'vol', 'contains', 'the', 'index', 'by', 'bomtz', '1831-70', 'didot', 'edition', '(greek', 'and', 'latin)', '5', 'vols', '1848', '74', 'english', 'translations', 'edited', 'by', 't', 'taylor', 'with', \"porphyry's\", 'introduction', '9', 'vols', '1812', 'under', 'editorship', 'of', 'j', 'a', 'smith', 'and', 'w', 'd', 'ross', 'ii', 'vols', '1908-31', 'loeb', 'editions', 'ethica', 'rhetorica', 'poetica', 'physica', 'politica', 'metaphysica', '1926-33', 'later', 'editions', 'of', 'separate', 'works', 'de', 'anima', 'torstrik', '1862', 'trendelenburg', '2nd', 'edition', '1877', 'with', 'english', 'translation', 'l', 'wallace', '1882', 'biehl', '1884', '1896', 'with', 'english', 'r', 'd', 'hicks', '1907', 'ethica', 'j', 's', 'brewer', '(nicomachean)', '1836', 'w', 'e', 'jelf', '1856', 'j', 'f', 't', 'rogers', '1865', 'a', 'grant', '1857', '8', '1866', '1874', '1885', 'e', 'moore', '1871', '1878', '4th', 'edition', '1890', 'ramsauer', '(nicomachean)', '1878', 'susemihl', '1878', '1880', 'revised', 'by', 'o', 'apelt', '1903', 'a', 'grant', '1885', 'i', 'bywater', '(nicomachean)', '1890', 'j', 'burnet', '1900', 'historia', 'animalium', 'schneider', '1812', 'aubert', 'and', 'wimmer', '1860;', 'dittmeyer', '1907', 'metaphysica', 'schwegler', '1848', 'w', 'christ', '1899', 'organon', 'waitz', '1844', '6', 'poetica', 'vahlen', '1867', '1874', 'with', 'notes', 'by', 'e', 'moore', '1875', 'with', 'english', 'translation', 'by', 'e', 'r', 'wharton', '1883', '1885', 'uberweg', '1870', '1875', 'with', 'german', 'translation', 'susemihl', '1874', 'schmidt', '1875', 'christ', '1878', 'i', 'bywater', '1898', 't', 'g', 'tucker', '1899', 'de', 'republica', 'athenientium', 'text', 'and', 'facsimile', 'of', 'papyrus', 'f', 'g', 'kenyon', '1891', '3rd', 'edition', '1892', 'kaibel', 'and', 'wilamowitz-moellendorf', '1891', '3rd', 'edition', '1898', 'van', 'herwerden', 'and', 'leeuwen', '(from', \"kenyon's\", 'text)', '1891', 'blass', '1892', '1895', '1898', '1903', 'j', 'e', 'sandys', '1893', 'politica', 'susemihl', '1872', 'with', 'german', '1878', '3rd', 'edition', '1882', 'susemihl', 'and', 'hicks', '1894', 'etc', 'o', 'immisch', '1909', 'physica', 'c', 'prantl', '1879', 'rhetorica', 'stahr', '1862', 'sprengel', '(with', 'latin', 'text)', '1867', 'cope', 'and', 'sandys', '1877', 'roemer', '1885', '1898', 'english', 'translations', 'of', 'one', 'or', 'more', 'works', 'de', 'anima', '(with', 'parva', 'naturalia)', 'by', 'w', 'a', 'hammond', '1902', 'ethica', 'of', 'morals', 'to', 'nicomachus', 'by', 'e', 'pargiter', '1745', 'with', 'politica', 'by', 'j', 'gillies', '1797', '1804', '1813', 'with', 'rhetorica', 'and', 'poetica', 'by', 't', 'taylor', '1818', 'and', 'later', 'editions', 'nicomachean', 'ethics', '1819', 'mainly', 'from', 'text', 'of', 'bekker', 'by', 'd', 'p', 'chase', '1847', 'revised', '1861', 'and', 'later', 'editions', 'with', 'an', 'introductory', 'essay', 'by', 'g', 'h', 'lewes', '(camelot', 'classics)', '1890', 're-edited', 'by', 'j', 'm', 'mitchell', '(new', 'universal', 'library)', '1906', '1910', 'by', 'r', 'w', 'browne', \"(bohn's\", 'classical', 'library)', '1848', 'etc', 'by', 'r', 'williams', '1869', '1876', 'by', 'w', 'm', 'hatch', 'and', 'others', '(with', 'translation', 'of', 'paraphrase', 'attributed', 'to', 'andronicus', 'of', 'rhodes)', 'edited', 'by', 'e', 'hatch', '1879', 'by', 'f', 'h', 'peters', '1881', 'j', 'e', 'c', 'welldon', '1892', 'j', 'gillies', \"(lubbock's\", 'hundred', 'books)', '1893', 'historia', 'animalium', 'by', 'r', 'creswell', \"(bonn's\", 'classical', 'library)', '1848', 'with', 'treatise', 'on', 'physiognomy', 'by', 't', 'taylor', '1809', 'metaphysica', 'by', 't', 'taylor', '1801', 'by', 'j', 'h', 'm', 'mahon', \"(bohn's\", 'classical', 'library)', '1848', 'organon', 'with', \"porphyry's\", 'introduction', 'by', 'o', 'f', 'owen', \"(bohn's\", 'classical', 'library)', '1848', 'posterior', 'analytics', 'e', 'poste', '1850', 'e', 's', 'bourchier', '1901', 'on', 'fallacies', 'e', 'poste', '1866', 'parva', 'naturaha', '(greek', 'and', 'english)', 'by', 'g', 'r', 't', 'ross', '1906', 'with', 'de', 'anima', 'by', 'w', 'a', 'hammond', '1902', 'youth', 'and', 'old', 'age', 'life', 'and', 'death', 'and', 'respiration', 'w', 'ogle', '1897', 'poetica', 'with', 'notes', 'from', 'the', 'french', 'of', 'd', 'acier', '1705', 'by', 'h', 'j', 'pye', '1788', '1792', 't', 'twining', '1789', '1812', 'with', 'preface', 'and', 'notes', 'by', 'h', 'hamilton', '1851', 'treatise', 'on', 'rhetorica', 'and', 'poetica', 'by', 't', 'hobbes', \"(bohn's\", 'classical', 'library)', '1850', 'by', 'wharton', '1883', '(see', 'greek', 'version)', 's', 'h', 'butcher', '1895', '1898', '3rd', 'edition', '1902', 'e', 's', 'bourchier', '1907', 'by', 'ingram', 'bywater', '1909', 'de', 'partibus', 'animalium', 'w', 'ogle', '1882', 'de', 'republica', 'athenientium', 'by', 'e', 'poste', '1891', 'f', 'g', 'kenyon', '1891', 't', 'j', 'dymes', '1891', 'de', 'virtutibus', 'et', 'vitus', 'by', 'w', 'bridgman', '1804', 'politica', 'from', 'the', 'french', 'of', 'regius', '1598', 'by', 'w', 'ellis', '1776', '1778', '1888', \"(morley's\", 'universal', 'library)', '1893', \"(lubbock's\", 'hundred', 'books)', 'by', 'e', 'walford', '(with', 'æconomics', 'and', 'life', 'by', 'dr', 'gillies)', \"(bohn's\", 'classical', 'library)', '1848', 'j', 'e', 'c', 'welldon', '1883', 'b', 'jowett', '1885', 'with', 'introduction', 'and', 'index', 'by', 'h', 'w', 'c', 'davis', '1905', 'books', 'i', 'iii', 'iv', '(vii)', 'from', \"bekker's\", 'text', 'by', 'w', 'e', 'bolland', 'with', 'introduction', 'by', 'a', 'lang', '1877']\n"
     ]
    }
   ],
   "source": [
    "all_reviews_as_line_separated_string=\"The 5th vol contains the Index by Bomtz,  1831-70, Didot edition (Greek and Latin), 5 vols 1848 74    ENGLISH TRANSLATIONS Edited by T Taylor, with Porphyry's Introduction,  9 vols, 1812, under editorship of J A Smith and W D Ross, II vols,  1908-31, Loeb editions Ethica, Rhetorica, Poetica, Physica, Politica,  Metaphysica, 1926-33    Later editions of separate works _De Anima_ Torstrik, 1862,  Trendelenburg, 2nd edition, 1877, with English translation, L Wallace,  1882, Biehl, 1884, 1896, with English, R D Hicks, 1907 _Ethica_ J S  Brewer (Nicomachean), 1836, W E Jelf, 1856, J F T Rogers, 1865, A  Grant, 1857 8, 1866, 1874, 1885, E Moore, 1871, 1878, 4th edition,  1890, Ramsauer (Nicomachean), 1878, Susemihl, 1878, 1880, revised by O  Apelt, 1903, A Grant, 1885, I Bywater (Nicomachean), 1890, J Burnet,  1900    _Historia Animalium_ Schneider, 1812, Aubert and Wimmer, 1860;  Dittmeyer, 1907    _Metaphysica_ Schwegler, 1848, W Christ, 1899    _Organon_ Waitz, 1844 6    _Poetica_ Vahlen, 1867, 1874, with Notes by E Moore, 1875, with English  translation by E R Wharton, 1883, 1885, Uberweg, 1870, 1875, with  German translation, Susemihl, 1874, Schmidt, 1875, Christ, 1878, I  Bywater, 1898, T G Tucker, 1899    _De Republica Athenientium_ Text and facsimile of Papyrus, F G Kenyon,  1891, 3rd edition, 1892, Kaibel and Wilamowitz-Moellendorf, 1891, 3rd  edition, 1898, Van Herwerden and Leeuwen (from Kenyon's text), 1891,  Blass, 1892, 1895, 1898, 1903, J E Sandys, 1893    _Politica_ Susemihl, 1872, with German, 1878, 3rd edition, 1882,  Susemihl and Hicks, 1894, etc, O Immisch, 1909    _Physica_ C Prantl, 1879    _Rhetorica_ Stahr, 1862, Sprengel (with Latin text), 1867, Cope and  Sandys, 1877, Roemer, 1885, 1898    ENGLISH TRANSLATIONS OF ONE OR MORE WORKS De Anima (with Parva  Naturalia), by W A Hammond, 1902 Ethica Of Morals to Nicomachus, by E  Pargiter, 1745, with Politica by J Gillies, 1797, 1804, 1813, with  Rhetorica and Poetica, by T Taylor, 1818, and later editions  Nicomachean Ethics, 1819, mainly from text of Bekker by D P Chase,  1847, revised 1861, and later editions, with an introductory essay by G  H Lewes (Camelot Classics) 1890, re-edited by J M Mitchell (New  Universal Library), 1906, 1910, by R W Browne (Bohn's Classical  Library), 1848, etc, by R Williams, 1869, 1876, by W M Hatch and others  (with translation of paraphrase attributed to Andronicus of Rhodes),  edited by E Hatch, 1879 by F H Peters, 1881, J E C Welldon, 1892, J  Gillies (Lubbock's Hundred Books) 1893 Historia Animalium, by R  Creswell (Bonn's Classical Library) 1848, with Treatise on Physiognomy,  by T Taylor, 1809 Metaphysica, by T Taylor, 1801, by J H M Mahon  (Bohn's Classical Library), 1848 Organon, with Porphyry's Introduction,  by O F Owen (Bohn's Classical Library), 1848 Posterior Analytics, E  Poste, 1850, E S Bourchier, 1901, On Fallacies, E Poste, 1866 Parva  Naturaha (Greek and English), by G R T Ross, 1906, with De Anima, by W  A Hammond, 1902 Youth and Old Age, Life and Death and Respiration, W  Ogle 1897 Poetica, with Notes from the French of D Acier, 1705, by H J  Pye, 1788, 1792, T Twining, 1789, 1812, with Preface and Notes by H  Hamilton, 1851, Treatise on Rhetorica and Poetica, by T Hobbes (Bohn's  Classical Library), 1850, by Wharton, 1883 (see Greek version), S H  Butcher, 1895, 1898, 3rd edition, 1902, E S Bourchier, 1907, by Ingram  Bywater, 1909 De Partibus Animalium, W Ogle, 1882 De Republica  Athenientium, by E Poste, 1891, F G Kenyon, 1891, T J Dymes, 1891 De  Virtutibus et Vitus, by W Bridgman, 1804 Politica, from the French of  Regius, 1598, by W Ellis, 1776, 1778, 1888 (Morley's Universal  Library), 1893 (Lubbock's Hundred Books) by E Walford (with Æconomics,  and Life by Dr Gillies), (Bohn's Classical Library), 1848, J E. C.  Welldon, 1883, B Jowett, 1885, with Introduction and Index by H W C  Davis, 1905, Books i iii iv (vii) from Bekker's text by W E Bolland,  with Introduction by A Lang, 1877.\"\n",
    "\n",
    "for line in all_reviews_as_line_separated_string.split(\"\\n\")[:10]:\n",
    "    print(\"\\nRaw text:\")\n",
    "    print(line)\n",
    "    print(\"Clean token list:\")\n",
    "    print(tokenize_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Building a fixed-size vocabulary\n",
    "\n",
    "We want to select candidate tokens for our vocabulary.\n",
    "\n",
    "Let's use the following *simple* rules to build our vocabulary\n",
    "\n",
    "* Keep any token that appears at least 4 times in our corpus (entire dataset)\n",
    "\n",
    "Why? If a token is *rare*, it might be difficult to learn a reliable pattern for how it can be used to predict sentiment, which is our ultimate goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_count_dict = dict()\n",
    "\n",
    "for line in all_reviews_as_line_separated_string.split(\"\\n\"):\n",
    "    tok_list = tokenize_text(line)\n",
    "    for tok in tok_list:\n",
    "        if tok in tok_count_dict:\n",
    "            tok_count_dict[tok] += 1\n",
    "        else:\n",
    "            tok_count_dict[tok] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 10 most common tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens = list(sorted(tok_count_dict, key=tok_count_dict.get, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 by\n",
      "   20 and\n",
      "   17 with\n",
      "   16 e\n",
      "   13 j\n",
      "   13 w\n",
      "   10 t\n",
      "   10 of\n",
      "    8 library)\n",
      "    7 edition\n"
     ]
    }
   ],
   "source": [
    "for w in sorted_tokens[:10]:\n",
    "    print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 10 least common tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1 jowett\n",
      "    1 davis\n",
      "    1 1905\n",
      "    1 books\n",
      "    1 iii\n",
      "    1 iv\n",
      "    1 (vii)\n",
      "    1 bekker's\n",
      "    1 bolland\n",
      "    1 lang\n"
     ]
    }
   ],
   "source": [
    "for w in sorted_tokens[-10:]:\n",
    "    print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary as list of all tokens that have count at least 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of strings that identify all tokens in our vocabulary\n",
    "# We'll use a *list comprehension*, a way in Python to cleaning select a subset of a larger list\n",
    "# by providing an if statement.\n",
    "\n",
    "vocab_list = [w for w in sorted_tokens if tok_count_dict[w] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 by\n",
      "   20 and\n",
      "   17 with\n",
      "   16 e\n",
      "   13 j\n",
      "   13 w\n",
      "   10 t\n",
      "   10 of\n",
      "    8 library)\n",
      "    7 edition\n",
      "    7 1848\n",
      "    7 de\n",
      "    7 h\n",
      "    6 a\n",
      "    6 r\n",
      "    6 1891\n",
      "    6 classical\n",
      "    5 english\n",
      "    5 poetica\n",
      "    5 f\n",
      "    5 1885\n",
      "    5 1878\n",
      "    5 1898\n",
      "    5 g\n",
      "    5 (bohn's\n",
      "    4 the\n",
      "    4 taylor\n",
      "    4 introduction\n",
      "    4 d\n",
      "    4 editions\n",
      "    4 rhetorica\n",
      "    4 politica\n",
      "    4 translation\n",
      "    4 s\n",
      "    4 susemihl\n",
      "    4 3rd\n",
      "    4 c\n",
      "    4 (with\n",
      "    4 from\n"
     ]
    }
   ],
   "source": [
    "for w in vocab_list:\n",
    "    print(\"%5d %s\" % (tok_count_dict[w], w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 2a: Do you see tokens in the vocabulary that might be useful for the sentiment prediction? What are they? Are there some that would never be useful? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO make a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b: How many tokens are in the chosen vocabulary? How many would there be if you used count at least 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Creating bag-of-words representation for individual review\n",
    "\n",
    "Now, given the vocabulary we defined above in part 2, let's turn each text into a count vector.\n",
    "\n",
    "Our goal is to write a method that can take each individual review text and produce a feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a dictionary that maps each vocab term in order to an integer defining its order in the vocab\n",
    "\n",
    "Each vocab term maps to a unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = dict()\n",
    "for vocab_id, tok in enumerate(vocab_list):\n",
    "    vocab_dict[tok] = vocab_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method to produce feature vector from provided text and the vocabulary (as a dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_into_feature_vector(text, vocab_dict):\n",
    "    ''' Produce count feature vector for provided text\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    text : string\n",
    "        A string of raw text, representing a single 'review'\n",
    "    vocab_dict : dict with string keys\n",
    "        If token is in vocabulary, will exist as key in the dict\n",
    "        If token is not in vocabulary, will not be in the dict\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    count_V : 1D numpy array, shape (V,) = (n_vocab,)\n",
    "        Count vector, indicating how often each vocab word\n",
    "        appears in the provided text string\n",
    "    '''\n",
    "    V = len(vocab_dict.keys())\n",
    "    count_V = np.zeros(V)\n",
    "    for tok in tokenize_text(text):\n",
    "        if tok in vocab_dict:\n",
    "            vv = vocab_dict[tok]\n",
    "            count_V[vv] += 1\n",
    "    return count_V\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example tranformations of short phrases\n",
    "\n",
    "Below, we'll try our count-vector transformation on several manually constructed short 'documents'\n",
    "\n",
    "* Common words: \"the was this\"\n",
    "* Positive words: \"good great fantastic\"\n",
    "* Negative words: \"bad horrible awful\"\n",
    "* Nonsense words: \"dinosaur nonsense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common words (should produce many positive entries in first few positions of the vector)\n",
    "transform_text_into_feature_vector(\"the was this the of a an of a\", vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive words (should produce a few positive entries!)\n",
    "transform_text_into_feature_vector(\"good great fantastic excellent good\", vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative words (should produce a few positive entries!)\n",
    "transform_text_into_feature_vector(\"bad worse awful terrible horrible\", vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rare / nonsense words (should produce an all-zero vector!)\n",
    "transform_text_into_feature_vector(\"dinosaur nonsense supercalifragilisticexpealidocious\", vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example tranformations of actual review (first row, index 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th vol contains the Index by Bomtz,  1831-70, Didot edition (Greek and Latin), 5 vols 1848 74    ENGLISH TRANSLATIONS Edited by T Taylor, with Porphyry's Introduction,  9 vols, 1812, under editorship of J A Smith and W D Ross, II vols,  1908-31, Loeb editions Ethica, Rhetorica, Poetica, Physica, Politica,  Metaphysica, 1926-33    Later editions of separate works _De Anima_ Torstrik, 1862,  Trendelenburg, 2nd edition, 1877, with English translation, L Wallace,  1882, Biehl, 1884, 1896, with English, R D Hicks, 1907 _Ethica_ J S  Brewer (Nicomachean), 1836, W E Jelf, 1856, J F T Rogers, 1865, A  Grant, 1857 8, 1866, 1874, 1885, E Moore, 1871, 1878, 4th edition,  1890, Ramsauer (Nicomachean), 1878, Susemihl, 1878, 1880, revised by O  Apelt, 1903, A Grant, 1885, I Bywater (Nicomachean), 1890, J Burnet,  1900    _Historia Animalium_ Schneider, 1812, Aubert and Wimmer, 1860;  Dittmeyer, 1907    _Metaphysica_ Schwegler, 1848, W Christ, 1899    _Organon_ Waitz, 1844 6    _Poetica_ Vahlen, 1867, 1874, with Notes by E Moore, 1875, with English  translation by E R Wharton, 1883, 1885, Uberweg, 1870, 1875, with  German translation, Susemihl, 1874, Schmidt, 1875, Christ, 1878, I  Bywater, 1898, T G Tucker, 1899    _De Republica Athenientium_ Text and facsimile of Papyrus, F G Kenyon,  1891, 3rd edition, 1892, Kaibel and Wilamowitz-Moellendorf, 1891, 3rd  edition, 1898, Van Herwerden and Leeuwen (from Kenyon's text), 1891,  Blass, 1892, 1895, 1898, 1903, J E Sandys, 1893    _Politica_ Susemihl, 1872, with German, 1878, 3rd edition, 1882,  Susemihl and Hicks, 1894, etc, O Immisch, 1909    _Physica_ C Prantl, 1879    _Rhetorica_ Stahr, 1862, Sprengel (with Latin text), 1867, Cope and  Sandys, 1877, Roemer, 1885, 1898    ENGLISH TRANSLATIONS OF ONE OR MORE WORKS De Anima (with Parva  Naturalia), by W A Hammond, 1902 Ethica Of Morals to Nicomachus, by E  Pargiter, 1745, with Politica by J Gillies, 1797, 1804, 1813, with  Rhetorica and Poetica, by T Taylor, 1818, and later editions  Nicomachean Ethics, 1819, mainly from text of Bekker by D P Chase,  1847, revised 1861, and later editions, with an introductory essay by G  H Lewes (Camelot Classics) 1890, re-edited by J M Mitchell (New  Universal Library), 1906, 1910, by R W Browne (Bohn's Classical  Library), 1848, etc, by R Williams, 1869, 1876, by W M Hatch and others  (with translation of paraphrase attributed to Andronicus of Rhodes),  edited by E Hatch, 1879 by F H Peters, 1881, J E C Welldon, 1892, J  Gillies (Lubbock's Hundred Books) 1893 Historia Animalium, by R  Creswell (Bonn's Classical Library) 1848, with Treatise on Physiognomy,  by T Taylor, 1809 Metaphysica, by T Taylor, 1801, by J H M Mahon  (Bohn's Classical Library), 1848 Organon, with Porphyry's Introduction,  by O F Owen (Bohn's Classical Library), 1848 Posterior Analytics, E  Poste, 1850, E S Bourchier, 1901, On Fallacies, E Poste, 1866 Parva  Naturaha (Greek and English), by G R T Ross, 1906, with De Anima, by W  A Hammond, 1902 Youth and Old Age, Life and Death and Respiration, W  Ogle 1897 Poetica, with Notes from the French of D Acier, 1705, by H J  Pye, 1788, 1792, T Twining, 1789, 1812, with Preface and Notes by H  Hamilton, 1851, Treatise on Rhetorica and Poetica, by T Hobbes (Bohn's  Classical Library), 1850, by Wharton, 1883 (see Greek version), S H  Butcher, 1895, 1898, 3rd edition, 1902, E S Bourchier, 1907, by Ingram  Bywater, 1909 De Partibus Animalium, W Ogle, 1882 De Republica  Athenientium, by E Poste, 1891, F G Kenyon, 1891, T J Dymes, 1891 De  Virtutibus et Vitus, by W Bridgman, 1804 Politica, from the French of  Regius, 1598, by W Ellis, 1776, 1778, 1888 (Morley's Universal  Library), 1893 (Lubbock's Hundred Books) by E Walford (with Æconomics,  and Life by Dr Gillies), (Bohn's Classical Library), 1848, J E. C.  Welldon, 1883, B Jowett, 1885, with Introduction and Index by H W C  Davis, 1905, Books i iii iv (vii) from Bekker's text by W E Bolland,  with Introduction by A Lang, 1877.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([37., 20., 17., 16., 13., 13., 10., 10.,  8.,  7.,  7.,  7.,  7.,\n",
       "        6.,  6.,  6.,  6.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text_0 = all_reviews_as_line_separated_string.split(\"\\n\")[0]\n",
    "print(raw_text_0)\n",
    "transform_text_into_feature_vector(raw_text_0, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example tranformations of actual review (index 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th vol contains the Index by Bomtz,  1831-70, Didot edition (Greek and Latin), 5 vols 1848 74    ENGLISH TRANSLATIONS Edited by T Taylor, with Porphyry's Introduction,  9 vols, 1812, under editorship of J A Smith and W D Ross, II vols,  1908-31, Loeb editions Ethica, Rhetorica, Poetica, Physica, Politica,  Metaphysica, 1926-33    Later editions of separate works _De Anima_ Torstrik, 1862,  Trendelenburg, 2nd edition, 1877, with English translation, L Wallace,  1882, Biehl, 1884, 1896, with English, R D Hicks, 1907 _Ethica_ J S  Brewer (Nicomachean), 1836, W E Jelf, 1856, J F T Rogers, 1865, A  Grant, 1857 8, 1866, 1874, 1885, E Moore, 1871, 1878, 4th edition,  1890, Ramsauer (Nicomachean), 1878, Susemihl, 1878, 1880, revised by O  Apelt, 1903, A Grant, 1885, I Bywater (Nicomachean), 1890, J Burnet,  1900    _Historia Animalium_ Schneider, 1812, Aubert and Wimmer, 1860;  Dittmeyer, 1907    _Metaphysica_ Schwegler, 1848, W Christ, 1899    _Organon_ Waitz, 1844 6    _Poetica_ Vahlen, 1867, 1874, with Notes by E Moore, 1875, with English  translation by E R Wharton, 1883, 1885, Uberweg, 1870, 1875, with  German translation, Susemihl, 1874, Schmidt, 1875, Christ, 1878, I  Bywater, 1898, T G Tucker, 1899    _De Republica Athenientium_ Text and facsimile of Papyrus, F G Kenyon,  1891, 3rd edition, 1892, Kaibel and Wilamowitz-Moellendorf, 1891, 3rd  edition, 1898, Van Herwerden and Leeuwen (from Kenyon's text), 1891,  Blass, 1892, 1895, 1898, 1903, J E Sandys, 1893    _Politica_ Susemihl, 1872, with German, 1878, 3rd edition, 1882,  Susemihl and Hicks, 1894, etc, O Immisch, 1909    _Physica_ C Prantl, 1879    _Rhetorica_ Stahr, 1862, Sprengel (with Latin text), 1867, Cope and  Sandys, 1877, Roemer, 1885, 1898    ENGLISH TRANSLATIONS OF ONE OR MORE WORKS De Anima (with Parva  Naturalia), by W A Hammond, 1902 Ethica Of Morals to Nicomachus, by E  Pargiter, 1745, with Politica by J Gillies, 1797, 1804, 1813, with  Rhetorica and Poetica, by T Taylor, 1818, and later editions  Nicomachean Ethics, 1819, mainly from text of Bekker by D P Chase,  1847, revised 1861, and later editions, with an introductory essay by G  H Lewes (Camelot Classics) 1890, re-edited by J M Mitchell (New  Universal Library), 1906, 1910, by R W Browne (Bohn's Classical  Library), 1848, etc, by R Williams, 1869, 1876, by W M Hatch and others  (with translation of paraphrase attributed to Andronicus of Rhodes),  edited by E Hatch, 1879 by F H Peters, 1881, J E C Welldon, 1892, J  Gillies (Lubbock's Hundred Books) 1893 Historia Animalium, by R  Creswell (Bonn's Classical Library) 1848, with Treatise on Physiognomy,  by T Taylor, 1809 Metaphysica, by T Taylor, 1801, by J H M Mahon  (Bohn's Classical Library), 1848 Organon, with Porphyry's Introduction,  by O F Owen (Bohn's Classical Library), 1848 Posterior Analytics, E  Poste, 1850, E S Bourchier, 1901, On Fallacies, E Poste, 1866 Parva  Naturaha (Greek and English), by G R T Ross, 1906, with De Anima, by W  A Hammond, 1902 Youth and Old Age, Life and Death and Respiration, W  Ogle 1897 Poetica, with Notes from the French of D Acier, 1705, by H J  Pye, 1788, 1792, T Twining, 1789, 1812, with Preface and Notes by H  Hamilton, 1851, Treatise on Rhetorica and Poetica, by T Hobbes (Bohn's  Classical Library), 1850, by Wharton, 1883 (see Greek version), S H  Butcher, 1895, 1898, 3rd edition, 1902, E S Bourchier, 1907, by Ingram  Bywater, 1909 De Partibus Animalium, W Ogle, 1882 De Republica  Athenientium, by E Poste, 1891, F G Kenyon, 1891, T J Dymes, 1891 De  Virtutibus et Vitus, by W Bridgman, 1804 Politica, from the French of  Regius, 1598, by W Ellis, 1776, 1778, 1888 (Morley's Universal  Library), 1893 (Lubbock's Hundred Books) by E Walford (with Æconomics,  and Life by Dr Gillies), (Bohn's Classical Library), 1848, J E. C.  Welldon, 1883, B Jowett, 1885, with Introduction and Index by H W C  Davis, 1905, Books i iii iv (vii) from Bekker's text by W E Bolland,  with Introduction by A Lang, 1877.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([37., 20., 17., 16., 13., 13., 10., 10.,  8.,  7.,  7.,  7.,  7.,\n",
       "        6.,  6.,  6.,  6.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text_101 = all_reviews_as_line_separated_string.split(\"\\n\")[0]\n",
    "print(raw_text_101)\n",
    "transform_text_into_feature_vector(raw_text_101, vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Using a bag-of-words representation for a classifier\n",
    "\n",
    "Let's show how we can classify text reviews using our BoW count feature representation.\n",
    "\n",
    "We'll assume we have N total reviews in our training set.\n",
    "\n",
    "We have defined a vocabulary of V terms (in part 2 above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(all_reviews_as_line_separated_string.split(\"\\n\"))\n",
    "V = len(vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the labels $y$ for all reviews\n",
    "\n",
    "We'll use knowledge that we built the raw dataset here by stacking many negative reviews then many positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_N = np.hstack([np.zeros(N//2), np.ones(N//2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to bow features $x$ for all reviews\n",
    "\n",
    "We need a feature matrix $X$ (with N rows and V features). We can do this just stacking all the transformed features from individual reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_NV = np.zeros((N, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn, raw_text_line in enumerate(all_reviews_as_line_separated_string.split(\"\\n\")):\n",
    "    x_tr_NV[nn] = transform_text_into_feature_vector(raw_text_line, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 39)\n"
     ]
    }
   ],
   "source": [
    "print(x_tr_NV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4a: How many times does each word in vocabulary appear in our training set?\n",
    "\n",
    "Hint: use np.sum with a specific axis specified, for the x_tr_NV array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a binary classifier\n",
    "\n",
    "Let's train a LogisticRegression classifier.\n",
    "\n",
    "We'll do 20 iters to keep it fast.\n",
    "\n",
    "Don't worry if you get warnings about convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just pick reasonable choices for quick demo\n",
    "# We may see a \"ConvergenceWarning\". That's fine for this demo.\n",
    "clf = sklearn.linear_model.LogisticRegression(\n",
    "    C=1000.0, max_iter=20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_tr_NV, y_tr_N)\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1224\u001b[0m     X,\n\u001b[0;32m   1225\u001b[0m     y,\n\u001b[0;32m   1226\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1228\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1230\u001b[0m )\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 0]"
     ]
    }
   ],
   "source": [
    "clf.fit(x_tr_NV, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is accuracy of our classifier on training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m yhat_tr_N \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_tr_NV)\n\u001b[0;32m      2\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean( y_tr_N \u001b[38;5;241m==\u001b[39m yhat_tr_N )\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining accuracy: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m acc)\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:360\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m        this class would be predicted.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    361\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    363\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ningn\\anaconda3\\envs\\cs135_25s_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "yhat_tr_N = clf.predict(x_tr_NV)\n",
    "acc = np.mean( y_tr_N == yhat_tr_N )\n",
    "\n",
    "print(\"Training accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the learned logistic regression weights for each token in our vocabulary?\n",
    "\n",
    "Each token in our vocabulary is a feature in our model.\n",
    "\n",
    "Logistic regression will learn one weight parameter for each feature (each vocab token)\n",
    "\n",
    "In the code below, we look at the learned weights, sort them from decreasing to increasing order, and then print them next to the corresponding feature. This might help us *interpret* what has been learned.\n",
    "\n",
    "Interpretation: \n",
    "* If a weight is very negative, the more that word appears, the more likely that review is a NEGATIVE sentiment one\n",
    "* If a weight is very positive, the more that word appears, the more likley that review is a POSITIVE sentiment one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weights_V \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m sorted_tok_ids_V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(weights_V)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vv \u001b[38;5;129;01min\u001b[39;00m sorted_tok_ids_V:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "weights_V = clf.coef_[0]\n",
    "sorted_tok_ids_V = np.argsort(weights_V)\n",
    "\n",
    "for vv in sorted_tok_ids_V:\n",
    "    print(\"% 7.3f %s\" % (weights_V[vv], vocab_list[vv]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 4b: Can you interpret these weights? What vocab terms would you expect to have large negative or large positive weights? Do they? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO discuss and make a list of what makes sense and what might not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4c: Try out your classifier on new data\n",
    "\n",
    "Below are the raw text of 20 possible reviews, which are NOT in the original dataset we used in Parts 1-3.\n",
    "\n",
    "What does your classifier predict for each one? Does your classifier generalize well to this new data?\n",
    "\n",
    "(You can use your human ability to read to decide what the labels should be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = \"\"\"Do not make the same mistake as me.\n",
    "I might have gotten a defect, but I would not risk buying it again because of the built quality alone.\n",
    "Not worth it.\n",
    "you could only take 2 videos at a time and the quality was very poor.\n",
    "If you plan to use this in a car forget about it.\n",
    "I have 2-3 bars on my cell phone when I am home, but you cant not hear anything.\n",
    "Battery has no life.\n",
    "The internet access was fine, it the rare instance that it worked.\n",
    "Saggy, floppy piece of junk.\n",
    "wont work right or atleast for me.\n",
    "Good service, very clean, and inexpensive, to boot!\n",
    "The owners are super friendly and the staff is courteous.\n",
    "Very good food, great atmosphere.1\n",
    "This was my first and only Vegas buffet and it did not disappoint.\n",
    "Interesting decor.\n",
    "Plus, it's only 8 bucks.\n",
    "Great steak, great sides, great wine, amazing desserts.\n",
    "Four stars for the food & the guy in the blue shirt for his great vibe & still letting us in to eat !\n",
    "The staff is great, the food is delish, and they have an incredible beer selection.\n",
    "Nargile - I think you are great\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a prediction for the first example test review\n",
    "x_V = transform_text_into_feature_vector(\"Not worth it.\", vocab_dict)\n",
    "clf.predict(x_V.reshape((1,V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make predictions for the 20 test reviews above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Using built-in sklearn tool: CountVectorizer\n",
    "\n",
    "Instead of writing manual code, you can use CountVectorizer class from sklearn.\n",
    "\n",
    "This class lets you do fast and repeatable BoW feature extraction given a dataset.\n",
    "\n",
    "You can control things like:\n",
    "\n",
    "* How to ignore rare vocab terms.\n",
    "* How to ignore too common vocab terms (like the, an, a that don't provide meaningful semantic content)\n",
    "* How to ignore punctuation\n",
    "* Whether to use single-word features, or ordered pairs (bigrams aka 2-grams) or even 3-grams.\n",
    "* Whether to produce count or binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up the docs for CountVectorizer\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "### Parameters of the CountVectorizer\n",
    "\n",
    "Here are all the settings you can control when you construct it.\n",
    "\n",
    "```\n",
    "Parameters\n",
    "----------\n",
    "input : string {'filename', 'file', 'content'}, default='content'\n",
    "    If 'filename', the sequence passed as an argument to fit is\n",
    "    expected to be a list of filenames that need reading to fetch\n",
    "    the raw content to analyze.\n",
    "\n",
    "    If 'file', the sequence items must have a 'read' method (file-like\n",
    "    object) that is called to fetch the bytes in memory.\n",
    "\n",
    "    Otherwise the input is expected to be a sequence of items that\n",
    "    can be of type string or byte.\n",
    "\n",
    "lowercase : bool, default=True\n",
    "    Convert all characters to lowercase before tokenizing.\n",
    "\n",
    "tokenizer : callable, default=None\n",
    "    Override the string tokenization step while preserving the\n",
    "    preprocessing and n-grams generation steps.\n",
    "    Only applies if ``analyzer == 'word'``.\n",
    "\n",
    "stop_words : string {'english'}, list, default=None\n",
    "    If 'english', a built-in stop word list for English is used.\n",
    "    There are several known issues with 'english' and you should\n",
    "    consider an alternative (see :ref:`stop_words`).\n",
    "\n",
    "    If a list, that list is assumed to contain stop words, all of which\n",
    "    will be removed from the resulting tokens.\n",
    "    Only applies if ``analyzer == 'word'``.\n",
    "\n",
    "    If None, no stop words will be used. max_df can be set to a value\n",
    "    in the range [0.7, 1.0) to automatically detect and filter stop\n",
    "    words based on intra corpus document frequency of terms.\n",
    "\n",
    "ngram_range : tuple (min_n, max_n), default=(1, 1)\n",
    "    The lower and upper boundary of the range of n-values for different\n",
    "    word n-grams or char n-grams to be extracted. All values of n such\n",
    "    such that min_n <= n <= max_n will be used. For example an\n",
    "    ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\n",
    "    unigrams and bigrams, and ``(2, 2)`` means only bigrams.\n",
    "    Only applies if ``analyzer is not callable``.\n",
    "\n",
    "analyzer : string, {'word', 'char', 'char_wb'} or callable,             default='word'\n",
    "    Whether the feature should be made of word n-gram or character\n",
    "    n-grams.\n",
    "    Option 'char_wb' creates character n-grams only from text inside\n",
    "    word boundaries; n-grams at the edges of words are padded with space.\n",
    "\n",
    "    If a callable is passed it is used to extract the sequence of features\n",
    "    out of the raw, unprocessed input.\n",
    "\n",
    "    .. versionchanged:: 0.21\n",
    "\n",
    "    Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n",
    "    first read from the file and then passed to the given callable\n",
    "    analyzer.\n",
    "\n",
    "max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "    When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly higher than the given threshold (corpus-specific\n",
    "    stop words).\n",
    "    If float, the parameter represents a proportion of documents, integer\n",
    "    absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "min_df : float in range [0.0, 1.0] or int, default=1\n",
    "    When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly lower than the given threshold. This value is also\n",
    "    called cut-off in the literature.\n",
    "    If float, the parameter represents a proportion of documents, integer\n",
    "    absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "max_features : int, default=None\n",
    "    If not None, build a vocabulary that only consider the top\n",
    "    max_features ordered by term frequency across the corpus.\n",
    "\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "vocabulary : Mapping or iterable, default=None\n",
    "    Either a Mapping (e.g., a dict) where keys are terms and values are\n",
    "    indices in the feature matrix, or an iterable over terms. If not\n",
    "    given, a vocabulary is determined from the input documents. Indices\n",
    "    in the mapping should not be repeated and should not have any gap\n",
    "    between 0 and the largest index.\n",
    "\n",
    "binary : bool, default=False\n",
    "    If True, all non zero counts are set to 1. This is useful for discrete\n",
    "    probabilistic models that model binary events rather than integer\n",
    "    counts.\n",
    "```\n",
    "\n",
    "### Attributes of the CountVectorizer\n",
    "\n",
    "After you fit the count vectorizer, you can access these attributes.\n",
    "\n",
    "```\n",
    "Attributes\n",
    "----------\n",
    "vocabulary_ : dict\n",
    "    A mapping of terms to feature indices.\n",
    "\n",
    "fixed_vocabulary_: boolean\n",
    "    True if a fixed vocabulary of term to indices mapping\n",
    "    is provided by the user\n",
    "\n",
    "stop_words_ : set\n",
    "    Terms that were ignored because they either:\n",
    "\n",
    "      - occurred in too many documents (`max_df`)\n",
    "      - occurred in too few documents (`min_df`)\n",
    "      - were cut off by feature selection (`max_features`).\n",
    "\n",
    "    This is only available if no vocabulary was given.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare our training data (make it an iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_training_text_reviews = all_reviews_as_line_separated_string.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CountVectorizer that uses our *predefined* vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_preprocessor = CountVectorizer(binary=False, vocabulary=vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(vocabulary={&quot;(bohn&#x27;s&quot;: 24, &#x27;(with&#x27;: 37, &#x27;1848&#x27;: 10, &#x27;1878&#x27;: 21,\n",
       "                            &#x27;1885&#x27;: 20, &#x27;1891&#x27;: 15, &#x27;1898&#x27;: 22, &#x27;3rd&#x27;: 35,\n",
       "                            &#x27;a&#x27;: 13, &#x27;and&#x27;: 1, &#x27;by&#x27;: 0, &#x27;c&#x27;: 36,\n",
       "                            &#x27;classical&#x27;: 16, &#x27;d&#x27;: 28, &#x27;de&#x27;: 11, &#x27;e&#x27;: 3,\n",
       "                            &#x27;edition&#x27;: 9, &#x27;editions&#x27;: 29, &#x27;english&#x27;: 17,\n",
       "                            &#x27;f&#x27;: 19, &#x27;from&#x27;: 38, &#x27;g&#x27;: 23, &#x27;h&#x27;: 12,\n",
       "                            &#x27;introduction&#x27;: 27, &#x27;j&#x27;: 4, &#x27;library)&#x27;: 8, &#x27;of&#x27;: 7,\n",
       "                            &#x27;poetica&#x27;: 18, &#x27;politica&#x27;: 31, &#x27;r&#x27;: 14, ...})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(vocabulary={&quot;(bohn&#x27;s&quot;: 24, &#x27;(with&#x27;: 37, &#x27;1848&#x27;: 10, &#x27;1878&#x27;: 21,\n",
       "                            &#x27;1885&#x27;: 20, &#x27;1891&#x27;: 15, &#x27;1898&#x27;: 22, &#x27;3rd&#x27;: 35,\n",
       "                            &#x27;a&#x27;: 13, &#x27;and&#x27;: 1, &#x27;by&#x27;: 0, &#x27;c&#x27;: 36,\n",
       "                            &#x27;classical&#x27;: 16, &#x27;d&#x27;: 28, &#x27;de&#x27;: 11, &#x27;e&#x27;: 3,\n",
       "                            &#x27;edition&#x27;: 9, &#x27;editions&#x27;: 29, &#x27;english&#x27;: 17,\n",
       "                            &#x27;f&#x27;: 19, &#x27;from&#x27;: 38, &#x27;g&#x27;: 23, &#x27;h&#x27;: 12,\n",
       "                            &#x27;introduction&#x27;: 27, &#x27;j&#x27;: 4, &#x27;library)&#x27;: 8, &#x27;of&#x27;: 7,\n",
       "                            &#x27;poetica&#x27;: 18, &#x27;politica&#x27;: 31, &#x27;r&#x27;: 14, ...})</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(vocabulary={\"(bohn's\": 24, '(with': 37, '1848': 10, '1878': 21,\n",
       "                            '1885': 20, '1891': 15, '1898': 22, '3rd': 35,\n",
       "                            'a': 13, 'and': 1, 'by': 0, 'c': 36,\n",
       "                            'classical': 16, 'd': 28, 'de': 11, 'e': 3,\n",
       "                            'edition': 9, 'editions': 29, 'english': 17,\n",
       "                            'f': 19, 'from': 38, 'g': 23, 'h': 12,\n",
       "                            'introduction': 27, 'j': 4, 'library)': 8, 'of': 7,\n",
       "                            'poetica': 18, 'politica': 31, 'r': 14, ...})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_preprocessor.fit(list_of_training_text_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we get the features?\n",
    "\n",
    "Use sklearn API's `transform` method of your trained extractor.\n",
    "\n",
    "This will deliver a SPARSE matrix representation (since so many entries are exactly zero, as most documents do not contain any instances of many vocab terms).\n",
    "\n",
    "In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the scipy.sparse package.\n",
    "\n",
    "See scipy.sparse docs for details: <https://docs.scipy.org/doc/scipy/reference/sparse.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(1, 39)\n"
     ]
    }
   ],
   "source": [
    "sparse_arr = bow_preprocessor.transform(list_of_training_text_reviews[:3])\n",
    "print(type(sparse_arr))\n",
    "print(sparse_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert to a dense representaiton via the `toarray()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 39)\n"
     ]
    }
   ],
   "source": [
    "dense_arr_3V = sparse_arr.toarray()\n",
    "print(type(dense_arr_3V))\n",
    "print(dense_arr_3V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the extracted count features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37, 20, 21,  0,  0,  0,  0, 10,  0,  7,  7,  5,  0,  0,  0,  6,\n",
       "         6,  6,  4,  0,  5,  5,  5,  0,  0,  4,  4,  4,  0,  4,  3,  3,\n",
       "         4,  0,  4,  4,  0,  0,  5]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_arr_3V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer that builds its own UNIGRAM vocabulary\n",
    "\n",
    "* ngram_range=(1,1) : Means it will use unigrams (individual tokens)\n",
    "* min_df=1 : Means include any term that occurs in at least one document in training set\n",
    "* max_df=1.0 : Means include any terms that appears in less than 100% (fraction of 1.0) of training docs\n",
    "* binary=False : means it will do counts, not just binary presence/absence of each vocab term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_preprocessor = CountVectorizer(ngram_range=(1,1), min_df=1, max_df=1.0, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_preprocessor.fit(list_of_training_text_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_preprocessor.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 243 the\n",
      "  74 5th\n",
      " 261 vol\n",
      " 122 contains\n",
      " 162 index\n",
      " 115 by\n",
      " 106 bomtz\n",
      "  16 1831\n",
      "  75 70\n",
      " 128 didot\n"
     ]
    }
   ],
   "source": [
    "for term, count in list(bow_preprocessor.vocabulary_.items())[:10]:\n",
    "    print(\"%4d %s\" % (count, term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: A Bag-of-Words CountVectorizer + Classifier pipeline\n",
    "\n",
    "If we do a *pipeline*, we can make sure that:\n",
    "\n",
    "1) We apply the same text transforms to training and text data\n",
    "\n",
    "2) We use nice sklearn functionality that you don't need to reinvent from scratch\n",
    "\n",
    "In this part, we'll show you how to combine CountVectorizer with a classifier, and do a *combined* grid search over relevant hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline : CountVectors + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bow_classifier_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('my_bow_feature_extractor', CountVectorizer(min_df=1, max_df=1.0, ngram_range=(1,1))),\n",
    "    ('my_classifier', sklearn.linear_model.LogisticRegression(C=1.0, max_iter=20, random_state=101)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparam grid to search\n",
    "\n",
    "Remember, for a *pipeline*, the name of each parameter is built by concatenating string names, like\n",
    "\n",
    "```\n",
    "<step_name>_<hyperparameter_name>\n",
    "```\n",
    "\n",
    "* where <step_name> is name of the step in the pipeline, like \"my_classifier\", which we defined when we created the pipeline\n",
    "* where <hyperparameter_name> is the name of the hyperparameter for that step, like \"C\" which is a known parameter for that step's sklearn class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameter_grid_by_name = dict()\n",
    "my_parameter_grid_by_name['my_bow_feature_extractor__min_df'] = [1, 2, 4]\n",
    "my_parameter_grid_by_name['my_classifier__C'] = np.logspace(-4, 4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scoring_metric_name = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a \"predefined\" split of our training data into train and validation (so we can do grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of training text reviews and labels\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the training labels have STRUCTURE, so we better scramble them when we define our split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 400 total examples. Let's randomly assign 100 to validation and 300 to training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(0)\n",
    "\n",
    "valid_ids = prng.choice(np.arange(N), size=100)\n",
    "\n",
    "valid_indicators_N = np.zeros(N)\n",
    "valid_indicators_N[valid_ids] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom searcher object with all our settings in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    my_bow_classifier_pipeline,\n",
    "    my_parameter_grid_by_name,\n",
    "    scoring=my_scoring_metric_name,\n",
    "    cv=my_splitter,\n",
    "    refit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the grid search\n",
    "\n",
    "Remember, we *expect some convergence warnings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mhughes/micromamba/envs/cs135_25s_env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([ 0,  0, ..., -1,  0])),\n",
       "             estimator=Pipeline(steps=[(&#x27;my_bow_feature_extractor&#x27;,\n",
       "                                        CountVectorizer()),\n",
       "                                       (&#x27;my_classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=20,\n",
       "                                                           random_state=101))]),\n",
       "             param_grid={&#x27;my_bow_feature_extractor__min_df&#x27;: [1, 2, 4],\n",
       "                         &#x27;my_classifier__C&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04])},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([ 0,  0, ..., -1,  0])),\n",
       "             estimator=Pipeline(steps=[(&#x27;my_bow_feature_extractor&#x27;,\n",
       "                                        CountVectorizer()),\n",
       "                                       (&#x27;my_classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=20,\n",
       "                                                           random_state=101))]),\n",
       "             param_grid={&#x27;my_bow_feature_extractor__min_df&#x27;: [1, 2, 4],\n",
       "                         &#x27;my_classifier__C&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04])},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;my_bow_feature_extractor&#x27;, CountVectorizer()),\n",
       "                (&#x27;my_classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=20, random_state=101))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=20, random_state=101)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([ 0,  0, ..., -1,  0])),\n",
       "             estimator=Pipeline(steps=[('my_bow_feature_extractor',\n",
       "                                        CountVectorizer()),\n",
       "                                       ('my_classifier',\n",
       "                                        LogisticRegression(max_iter=20,\n",
       "                                                           random_state=101))]),\n",
       "             param_grid={'my_bow_feature_extractor__min_df': [1, 2, 4],\n",
       "                         'my_classifier__C': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04])},\n",
       "             refit=False, scoring='accuracy')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searcher.fit(list_of_training_text_reviews, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "\n",
    "param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
    "\n",
    "# Rearrange row order so it is easy to skim\n",
    "gsearch_results_df.sort_values(param_keys, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the results of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_my_bow_feature_extractor__min_df</th>\n",
       "      <th>param_my_classifier__C</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.498413</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.501587</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.787302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.498413</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.501587</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.726984</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.749206</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.498413</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.498413</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.726984</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_my_bow_feature_extractor__min_df  param_my_classifier__C  \\\n",
       "0                                        1                  0.0001   \n",
       "1                                        1                  0.0010   \n",
       "2                                        1                  0.0100   \n",
       "3                                        1                  0.1000   \n",
       "4                                        1                  1.0000   \n",
       "5                                        1                 10.0000   \n",
       "6                                        1                100.0000   \n",
       "7                                        1               1000.0000   \n",
       "8                                        1              10000.0000   \n",
       "9                                        2                  0.0001   \n",
       "10                                       2                  0.0010   \n",
       "11                                       2                  0.0100   \n",
       "12                                       2                  0.1000   \n",
       "13                                       2                  1.0000   \n",
       "14                                       2                 10.0000   \n",
       "15                                       2                100.0000   \n",
       "16                                       2               1000.0000   \n",
       "17                                       2              10000.0000   \n",
       "18                                       4                  0.0001   \n",
       "19                                       4                  0.0010   \n",
       "20                                       4                  0.0100   \n",
       "21                                       4                  0.1000   \n",
       "22                                       4                  1.0000   \n",
       "23                                       4                 10.0000   \n",
       "24                                       4                100.0000   \n",
       "25                                       4               1000.0000   \n",
       "26                                       4              10000.0000   \n",
       "\n",
       "    split0_test_score  rank_test_score  \n",
       "0            0.498413               24  \n",
       "1            0.501587               22  \n",
       "2            0.720635               15  \n",
       "3            0.777778                8  \n",
       "4            0.780952                6  \n",
       "5            0.793651                2  \n",
       "6            0.787302                5  \n",
       "7            0.790476                3  \n",
       "8            0.796825                1  \n",
       "9            0.498413               24  \n",
       "10           0.501587               22  \n",
       "11           0.704762               17  \n",
       "12           0.761905                9  \n",
       "13           0.780952                6  \n",
       "14           0.790476                3  \n",
       "15           0.746032               11  \n",
       "16           0.726984               13  \n",
       "17           0.749206               10  \n",
       "18           0.498413               24  \n",
       "19           0.498413               24  \n",
       "20           0.688889               19  \n",
       "21           0.726984               13  \n",
       "22           0.736508               12  \n",
       "23           0.711111               16  \n",
       "24           0.701587               18  \n",
       "25           0.682540               20  \n",
       "26           0.676190               21  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch_results_df[param_keys + ['split0_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion 6a: Which settings of min_df seem to perform best? Why do you think that is?\n",
    "\n",
    "Hint: Which settings produce more features and which produce less? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_25s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
